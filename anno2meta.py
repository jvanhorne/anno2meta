#!/usr/bin/env python
'''
Script to update meta files for an Electric Accelerator build with command
output and file access ifnormation.
This parses the annofile generated by emake and reads the .json files generated
by ecb2g to determine which build targets would have been meta mode targets
for bmake. For those, it updates the .meta files with the command output and
the file accesses as recorded in the annofile.

This consists of three classes. 
 - The AnnoFile class parses the annofile and collects environment information. 
 - The MetaTgt class records information for targets that are meta targets.
 - The MakeState class simply records the state of Makes. It contains no
methods.
'''

import argparse
import copy
import json
import logging
import os
import re
import resource
import sys
import urllib
import xml.etree.ElementTree as ET

# add path where we expect pyannolib to be
# XXX should not hard-code Ubuntu release, or architecture for that matter,
# but pyannolib is available only at this path for the moment.
pyannolibpath = '/volume/hab/Linux/Ubuntu-12.04/x86_64/pyannolib/current/lib/python2.7/site-packages'
if 'PYANNOLIBPATH' in os.environ:
    pyannolibpath = os.environ['PYANNOLIBPATH']
sys.path.append(pyannolibpath)
from pyannolib import annolib

# Globals for options and logging
check_level = False
debug_dirs_re = None

# Global functions
def getVal(conf, key, default=''):
    '''Get a value from a dictionary, or supply the default value if
       the key does not exist in the dictionary.
    '''
    try:
        return conf[key]
    except KeyError:
        return default

def escape_shchars(string, addDot=True, debug=False):
    '''Take bmake variable values and escape any shell characters. 
    '''
    if debug:
        logger.info('escape_shchars given='+string+' addDot is '
                     +repr(addDot))
    backslash_seen = False
    new_string = ''
    for ch in string:
        if backslash_seen == True:
            backslash_seen = False
            new_string += ch
        elif ch == '\\':
            backslash_seen = True
            new_string += ch
        elif ch in '.^+?{}[]':
            new_string += '\\'
            new_string += ch
        elif ch == '*' and addDot:
            new_string += '.'
            new_string += '*'
        else:
            new_string += ch
    if debug:
        logger.info('escape_shchars returning='+new_string)
    return new_string

def metaRelPath(filepath, cwd):
    # like meta_name() in bmake, if the targetname is in a different
    # directory, replace path separators with '_'
    if os.sep in filepath:
        normpath = os.path.normpath(os.path.join(cwd, filepath))
        relpath = os.path.relpath(normpath, cwd)
        if os.sep in relpath:
            tmp_metaName = os.path.join(cwd, relpath+'.meta')
            return tmp_metaName.replace(os.sep, '_')
        else:
            filepath = relpath
    return filepath+'.meta'

def metaFullPath(filepath, cwd):
    # like metaRelPath above but return the full path
    if os.sep in filepath:
        normpath = os.path.normpath(os.path.join(cwd, filepath))
        relpath = os.path.relpath(normpath, cwd)
        if os.sep in relpath:
            tmp_metaName = os.path.join(cwd, relpath+'.meta')
            return os.path.join(cwd, tmp_metaName.replace(os.sep, '_'))
        else:
            filepath = relpath
    return os.path.join(cwd, filepath+'.meta')

class MakeState:
    def __init__(self, env={}, cwd=''):
        '''
        env            is a dict of environment and make variables.
        metaTgts       is a dict of MetaTgts we are tracing
	'''
	self.env = env
	self.env['cwd'] = cwd
        self.metaTgts = {}
        self.varsRead = False

    def debug_me(self):
        return debug_dirs_re is not None and 'cwd' in self.env \
               and debug_dirs_re.search(self.env['cwd']) is not None

    def debug(self, string):
        if self.debug_me():
            logger.info(string+' cwd '+self.env['cwd'])

    def readVars(self, filename):
        logger.debug('starting')
        self.varsRead = True
        with open(filename+'.json') as fp:
            self.env.update(json.load(fp))
        logger.debug('done')

    # .MAKE.META.CREATED is set at makefile translation time,
    # not at actual build time. It is possible for a target to
    # have been built by a build before this one. If so, don't
    # overwrite it.
    def meta_written_already(self, mf):
        with open(mf) as mf_fp:
            for line in mf_fp:
                if line == metaBoilerPlate1:
                    return True
        return False

    def write_metas(self):
        if __debug__:
            self.debug('cwd = '+self.env['cwd']+
                   ' size of metaTgts: '+repr(len(self.metaTgts))+
                   ' writing metas for '+' '.join(self.metaTgts.keys()))
        tgtsToWrite = [ tgt for tgt in self.metaTgts.itervalues() \
                           if (tgt.meta_file in getVal(self.env,
                                                   '.MAKE.META.CREATED', '')) \
                           and not self.meta_written_already(tgt.meta_file) ]
        map(MetaTgt.write_meta, tgtsToWrite)
        logger.debug(self.env['cwd']+' done mapping')
        del self.metaTgts

    def make1_done(self):
        self.write_metas()

'''
MetaTgt
'''
# Globals for MetaTgt
# translate annofile op_type string to filemon character code
accessxlate = { 'create' : 'W',
                'link'   : 'L',
                'modify' : 'W',
                'read'   : 'R',
                'rename' : 'M',
                'unlink' : 'D',
              }

metaBoilerPlate1 = '-- EFS acquired metadata --\n'
metaBoilerPlate = \
          metaBoilerPlate1 \
        + '# Claim filemon version 3 so writes will be treated as reads,\n' \
        + 'V 3\n'

class MetaTgt:
    def __init__(self, cwd, targetname):
        self.cwd = cwd
        self.targetname = targetname
        self.accesses = []
        self.outputs = []
        self.meta_file = metaFullPath(self.targetname, self.cwd)

    def debug(self, string):
        if debug_dirs_re is not None and \
                debug_dirs_re.search(self.cwd) is not None:
            logger.info(string+' target '+self.targetname)

    def write_meta(self):
        if not os.path.exists(self.meta_file):
            logger.debug(self.meta_file+' non existent')
            return
        meta_fp = open(self.meta_file, 'a')
        # protect against non-printable characters
        outputlines = [ re.sub(r'[^\x00-\x7f]', r'.', output)+'\n' 
                            for output in self.outputs ]
        outBuf = ''.join(outputlines)
        outBuf += metaBoilerPlate
        for accesstype, filename, other in self.accesses:
            if accesstype == 'modify' or accesstype == 'create':
                outBuf += accessxlate['read']+' '+'0000'+' '+filename+'\n'
                outBuf += accessxlate[accesstype]+' '+'0000'+' '+filename+'\n'
            elif accesstype == 'link':
                if filename.startswith(self.cwd):
                    basename = filename[len(self.cwd)+1:]
                else:
                    basename=filename
                if other != '':
                    outBuf += accessxlate[accesstype]+' '+'0000'+ \
                                  ' \''+other+'\' \''+basename+'\'\n'
                else:
                    outBuf += accessxlate[accesstype]+' '+'0000'+ \
                                  ' \''+other+'\' \''+basename+'\'\n'
            else:
                outBuf += accessxlate[accesstype]+' '+'0000'+ \
                              ' '+filename+' '+other+'\n'
        try:
            meta_fp.write(outBuf)
        except UnicodeEncodeError:
            logger.warning(self.meta_file+' has non-uuencodabel characters')
        meta_fp.close()

    def add_access(self, filename, accesstype, other):
        if __debug__:
            self.debug(filename+' '+accesstype+' '+other)
        self.accesses.append([accesstype, filename, other])

'''
AnnoFile
The AnnoFile class reads the annofile from a build and calls MakeState
methods appropriately so that file accesses can be written to meta files
as they would have been collected by filemon.
The annofile is read using PyAnnoLib's file-follow capability, so that it
can be read while the build is writing to it.

AnnoFile is implemented in a sort of finite state machine. The states
are:
    StartState		The starting start.
    Make0State		The make level 0 element is being parsed, but no jobs
			are currently being parsed.
    Make1State		The make level 1 element is being parsed, but none of
			its jobs are currently being parsed.
    MakeNState		The make level N element where N>1 is being parsed,
			but none of its jobs are currently being parsed. The
			exact level is kept by the size of the 
			saved_make_states stack.
    JobState		A job element is being parsed but is not currently
			being traced.
    JobReadState	A job element is being parsed and its file accesses
			(op elements) are being traced.
    FailedState		A job failed 
    EndState		The make level 0 element has been completely parsed.

Reading particular tags act as the events to change the state. The tags and
their main actions are, listed closely in the order that they would appear
in the annofile (the preceding "/" means the end tag):
    make	Read the make level and current working directory, move
		state to Make?State, where ? depends upon the level.
    job		If in a non-zero Make state, and the job might be traced
		move to JobState and record the name of the job target. 
    /op		If in JobReadState, record file accesses appropriately. 
    /job	Return to appropriate Make?State.
    /make	If in Make1State or MakeNState, invoke DependFile, passing
		environment, targets, and file reads.
    failed	Clear set of file reads, go to FailedState

The xml.etree.ElementTree library's iterparse method is used to parse the
annofile. Based on the event that it returns, the process_elem method
dispatches processing of the entry using the "dispatch" dict which maps
events to the methods which handle them. 

AnnoFile keeps a stack of MakeStates (saved_make_states) because submakes
and jobs within makes can vary their environments, target lists, etc.

There is an issue with how build information is organized within the
annofile. In case a target is made with a submake, the XML element for the
parent job ends, and then the submake's element begins, followed eventually
by whatever job elements are part of the submake. When the submake element
ends, a continuation job element begins to handle any other commands for the
target. For this reason, we record the job ID and keep a dict mapping job
ID's to target names so we can properly record the continuation job info.

There is a special case where targets are generated by submakes which require
special treatment.  An example of this is the "help" or "mif" targets in
pkgs/Makefile.inc, where the target is built by a submake which does not run
in meta mode but the target is marked as ".META" by the parent make. In a
bmake build, the parent bmake would trace this since it is running in meta
mode and the target is marked as ".META". In an EA build, the submake's ecb2g
will not create meta files since it is not in meta mode. The annofile will
show that the parent job is a submake, and then a new make starts. anno2meta
recoreds the submake in the traceSubmake attribute, which is used in the
do_job_start of the new make.
'''

# Globals for AnnoFile: the states of the class
StartState, Make0State, Make1State, MakeNState, JobState, JobReadState, \
    FailedState, EndState = range(8)
state2str = ['StartState', 'Make0State', 'Make1State', 'MakeNState',
             'JobState', 'JobReadState', 'FailedState', 'EndState']

class AnnoFile:
    def __init__(self,filename):
        self.filename = filename
        self.state = StartState
        # tags we care about in the annofile
        self.tags = ['failed', 'job', 'make', 'op', 'output']
        # This dict, combined with the process_elem method below, implements
        # a sort of poor man's finite state machine. Based on the element, 
        # a method is invoked to process it.
        self.dispatch = {'failed-start' : self.do_failed_start,
                         'job-start' : self.do_job_start,
                         'job-end' : self.do_job_end,
                         'make-start' : self.do_make_start,
                         'make-end' : self.do_make_end,
                         'op-end' : self.do_op_end,
                         'output-end' : self.do_output_end,
                        }

        self.saved_make_states = []
        self.cur_make_state = None

        self.job2tgt = {}    # dict of job id's to their targets and whether
                             # they are in JobReadState, for use when submake
                             # is run in .META mode which interrupts job
        self.curMetaTgt = None   # the current MetaTgt object
        self.traceSubmake = False   # whether a submake job is to be traced

    def debug_me(self):
        return debug_dirs_re is not None and 'cwd' in self.cur_make_state.env \
               and debug_dirs_re.search(self.cur_make_state.env['cwd']) is not None

    def debug(self, string):
        if self.debug_me():
            logger.info(string+' state '+state2str[self.state]
                        +' level '+repr(len(self.saved_make_states)))

    def do_make_start(self, elem):
        elem_level = int(elem.attrib['level'])
        elem_cwd = elem.attrib['cwd']
        if self.state != StartState and self.state != EndState:
            self.saved_make_states.append(self.cur_make_state)
            self.cur_make_state = MakeState(env=self.cur_make_state.env.copy(), cwd=elem_cwd)
        else:
            self.cur_make_state = MakeState(env=os.environ.copy(), cwd=elem_cwd)
        expected_level = len(self.saved_make_states)
        # validate the make level, because we've seen problems with annofiles
        if elem_level != expected_level:
            if check_level:
                log_this_way = logger.error
            else:
                log_this_way = logger.warning
            log_this_way('level mismatch in '+elem_cwd+' cmd '+elem.attrib['cmd'])
            log_this_way('expected level='+repr(expected_level))
            log_this_way('new level='+repr(elem_level))
            if check_level:
                raise ValueError
        #logger.info('cwd = '+self.cur_make_state.env['cwd'])
        if __debug__:
            self.debug('set cwd = '+self.cur_make_state.env['cwd'])
        # save make state
        if self.state == StartState or self.state == EndState:
            self.state = Make0State
        elif self.state == Make0State:
            self.state = Make1State
        else: # self.state == Make1State or self.state == MakeNState
            self.state = MakeNState

    def do_make_end(self, elem):
        if __debug__:
            self.debug('starting')
        self.traceSubmake = False
        level = len(self.saved_make_states)
        # if in any MakeState we should write meta files
        # and if level 1 make, write .depend and DEPENDFILE
        if self.state == MakeNState:
            self.cur_make_state.write_metas()
            if level == 1:
                self.state = Make1State
            else:
                self.state = MakeNState
            del self.cur_make_state
            self.cur_make_state = self.saved_make_states.pop()
        elif self.state == Make1State:
            self.cur_make_state.write_metas()
            # clear flags and curenv 
            self.state = Make0State
            # del self.cur_make_state
            self.cur_make_state = self.saved_make_states.pop()
        elif self.state == FailedState:
            # preserve failed state for parent makes so that they
            # do not update dependencies, up to the level 0 make.
            if level == 0:
                self.state = EndState
            elif level == 1:
                self.state = Make0State
                del self.cur_make_state
                self.cur_make_state = self.saved_make_states.pop()
            else:
                del self.cur_make_state
                self.cur_make_state = self.saved_make_states.pop()
        else: # self.state == Make0State
            self.state = EndState

    def do_job_start(self, elem):
        if (self.state != Make1State and self.state != MakeNState):
            return
        if elem.attrib['type'] == 'rule':
            if 'status' in elem.attrib and \
                elem.attrib['status'] != 'rerun' and \
                elem.attrib['status'] != 'normal':
                    return
            cur_make_state = self.cur_make_state
            tgtname = urllib.unquote(elem.attrib['name'])
            # targets may be specified by absolute or non-normalized pathnames
            # even if they are in the current directory
            if __debug__:
                self.debug('cwd '+ cur_make_state.env['cwd']+
                           ' tgtname '+tgtname)
            if os.path.isabs(tgtname):
                if __debug__:
                    self.debug('tgtname '+tgtname+' is absolute')
                tgtname = os.path.relpath(tgtname, cur_make_state.env['cwd'])
                if __debug__:
                    self.debug('using tgtname '+tgtname)
            cur_id = elem.attrib['id']
            if not cur_make_state.varsRead:
                # the job start element contains the path to the makefile,
                # so now we can read it to get the unexported make variables
                cur_makefile = elem.attrib['file']
                cur_make_state.readVars(cur_makefile)

            tgtmetaname = metaRelPath(tgtname, cur_make_state.env['cwd'])
            tgtmetafullname = os.path.join(cur_make_state.env['cwd'],
                                           tgtmetaname)
            if __debug__:
                self.debug('tgt meta name is '+tgtmetaname+
                           ' tgt meta fullname is '+tgtmetafullname)
            if tgtmetafullname in getVal(cur_make_state.env,
                                         '.MAKE.META.CREATED', ''):
                # this target is a meta mode target. trace it.
                # save current target in case this job is split
                # XXX should we do this for all cases?
                if __debug__:
                    self.debug('reading tgtname = '+tgtname)
                self.state = JobReadState
                self.job2tgt[cur_id] = [tgtname, True]
                if tgtname in cur_make_state.metaTgts:
                    self.curMetaTgt = cur_make_state.metaTgts[tgtname]
                else:
                    if __debug__:
                        self.debug('adding MetaTgt for '+tgtname)
                    self.curMetaTgt = MetaTgt(cur_make_state.env['cwd'], tgtname)
                    cur_make_state.metaTgts[tgtname] = self.curMetaTgt
            elif self.curMetaTgt is not None and self.traceSubmake:
                if __debug__:
                    self.debug('testing '+self.curMetaTgt.meta_file)
                if os.path.exists(self.curMetaTgt.meta_file):
                    # if this is a job that is part of a submake which
                    # was a .META target for the parent make, use the 
                    # parent make, use the parent make's tgt
                    if __debug__:
                        self.debug('reading tgtname = '+
                                    elem.attrib['name']+' as '+
                                    self.curMetaTgt.targetname)
                    self.state = JobReadState
                    self.job2tgt[cur_id] = [ self.curMetaTgt.targetname, True ]
                else:
                    if __debug__:
                        self.debug('metapath not found')
            else:
                if __debug__:
                    self.debug('meta file not found')
                self.state = JobState
                self.job2tgt[cur_id] = [ tgtname, False ]

        elif elem.attrib['type'] == 'continuation':
            if 'status' in elem.attrib and \
                elem.attrib['status'] != 'rerun' and \
                elem.attrib['status'] != 'normal':
                    return
            # recover the primary job's tgt
            # XXX recover MetaTgt obj
            continued_job = self.job2tgt[elem.attrib['partof']]
            tgtname = continued_job[0]
            if tgtname in self.cur_make_state.metaTgts:
                self.curMetaTgt = self.cur_make_state.metaTgts[tgtname]
                if continued_job[1]:
                    self.state = JobReadState
                    if __debug__:
                        self.debug('continuing reading job '+
                                   repr(elem.attrib['partof'])+
                                   ' tgt '+continued_job[0])
            else:    # this job wasn't being traced
                self.state = JobState
                if __debug__:
                    self.debug('continuing job '+repr(elem.attrib['partof'])+
                               ' tgtname '+continued_job[0])

    def do_job_end(self, elem):
        if __debug__:
            self.debug('starting')
        if self.state == JobState or self.state == JobReadState:
            level = len(self.saved_make_states)
            if level > 1:
                self.state = MakeNState
            elif level == 1:
                self.state = Make1State
            else:
                self.state = Make0State
        elif self.state == StartState:
            logger.warning('in unexpected state')

    def do_failed_start(self, elem):
        if __debug__:
            self.debug('starting')
        if self.state == FailedState:
            return
        self.state = FailedState

    def do_op_end(self, elem):
        '''
        If we are tracing this job, collect all of the file accesses
        into a list to be used to generate the meta file. The possible
        types of <op> are:
            create filename [filetype]
            link filename other
            marker
            modify filename
            modifyAttrs filename atts
            read filename [filetype]
            submake filename [filetype]
            unlink filename [filetype]
        We ignore marker, modifyAttrs and submake. For
        "create filename symlink" we report as "link" and have to come up
        with "other", since EFS does not report it. Also, we go through
        some effort because EFS and filemon report reading symlinks 
        differently.
        '''
        if self.state != JobReadState:
            return
        op_type = elem.attrib['type']
        if op_type == 'submake':
            self.traceSubmake = True
            return
        if op_type == 'marker' or op_type == 'modifyAttrs':
            return
        # the filename may have characters that were escaped when written
        # in the annofile.
        filename = urllib.unquote(elem.attrib['file'])
        if filename[-5:] == '.meta':
            # ecb2g creates meta files. Do nothing with them.
            return
        try:
            filetype = elem.attrib['filetype']
        except KeyError:
            filetype = 'file'
        if __debug__:
            self.debug('access: '+op_type+' '+elem.attrib['file']+' '+filetype)
        add_access = self.curMetaTgt.add_access
        if op_type == 'read' or op_type == 'modify':
            if filetype == 'file' or filetype == 'symlink':
                add_access(filename, op_type, '')
            elif filetype == 'dir':
                # don't record reads of the current directory
                if filename != self.cur_make_state.env['cwd']:
                    add_access(filename, op_type, '')
        # if we create a symlink in our objdir to someplace else,
        # consider it a read of the target
        elif op_type == 'create':
            if filetype == 'symlink':
                # figure out the target of the symlink.
                if os.path.islink(filename):
                    add_access(elem.attrib['file'], 'link',
                                           os.readlink(filename))
                elif '/kernel/' in filename:
                    # we are in a case where one step of the build 
                    # has created a symlink and a later step has 
                    # removed it. We hack this by testing for the
                    # known cases and filling in what these links
                    # have been historically
                    other = filename.replace('/kernel/', '/config/')
                    add_access(elem.attrib['file'], 'link', other)
                elif not '/packages/sets/active/' in filename:
                    logger.info('unknown '+ 'stale symlink '+filename+' '+
                                self.cur_make_state.env['cwd'])
            else:
                add_access(elem.attrib['file'], op_type, '')
        elif op_type == 'unlink':
            add_access(filename, op_type, '')
        elif op_type == 'link' or op_type == 'rename':
            other = urllib.unquote(elem.attrib['other'])
            add_access(filename, op_type, other)
 
    def do_output_end(self, elem):
        if self.state == JobReadState:
            self.curMetaTgt.outputs.append(elem.text)

    def process_elem(self, event, elem):
        if elem.tag+'-'+event in self.dispatch:
            self.dispatch[elem.tag+'-'+event](elem)

    def parse(self, follow=False):
        if follow:
            fh = annolib.anno_follow(self.filename)
        else:
            fh = annolib.anno_open(self.filename)
        logger.info('start parsing file.')
        for event, elem in ET.iterparse(fh, events=['start','end']):
            # logger.debug(event+' '+elem.tag)
            if elem.tag in self.tags:
                self.process_elem(event, elem)
            if event == 'end':
                elem.clear()
            if self.state == EndState:
                break
        logger.info('end file parsing.')
        fh.close()

def main(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument('annofile', action='store')
    parser.add_argument('-d', '--debug', help='display debug info',
                        action='store_true')
    parser.add_argument('-l', '--logfile', help='logfile name', action='store')
    parser.add_argument('-f', '--follow', help='follow the annofile', action='store_true')
    parser.add_argument('-c', help='check make level', action='store_true')
    parser.add_argument('-t', help='trace (debug) dirs by regex', action='store')
    parser.add_argument('-u', help='display resource usage', action='store_true')
    args = parser.parse_args()
    if args.debug:
        my_log_level=logging.DEBUG
    else:
        my_log_level=logging.INFO

    global logfile
    global logger
    if args.logfile:
        logfile=args.logfile
    else:
        logfile=''

    logger = logging.getLogger()
    logger.setLevel(my_log_level)
    if len(logfile) > 0:
        hndlr = logging.FileHandler(logfile)
    else:
        hndlr = logging.StreamHandler()
    hndlr.setFormatter(logging.Formatter('%(asctime)s %(funcName)s %(message)s'))
    hndlr.setLevel(my_log_level)
    logger.addHandler(hndlr)

    if args.follow:
        follow = True
    else:
        follow = False

    if args.c:
        global check_level
        check_level = True
        logger.debug('check make level')
    if args.t:
        global debug_dirs_re
        debug_dirs_re=re.compile(escape_shchars(args.t, False))

    af = AnnoFile(args.annofile)
    af.parse(follow=follow)

    if args.u:
        usage = resource.getrusage(resource.RUSAGE_SELF)
        for name, desc in [ ('ru_maxrss', 'Max. Resident Set Size'),
                            ('ru_ixrss', 'Shared Memory Size'),
                            ('ru_idrss', 'Unshared Memory Size'),
                            ('ru_isrss', 'Stack Size'),
                          ]:
            logger.info('%-25s (%-10s) = %s' % (desc, name, getattr(usage, name)))

if __name__ == '__main__':
    try:
        main(sys.argv)
    except:
        print 'Error: ', sys.exc_info()[1]
        raise
